 GPT 40 model is here and one of the main questions is what can I use this for and that's why today we'll be looking at all the different use cases that open eyes showed us but also what the internet has come up with so far if you want to learn about the details of this announcement what it includes and how it works I created a separate video on that that I'll link on screen right now but with that being said let's get into some of the first use cases starting out with their announcement block post but I'll be adding in various use cases that I found across the internet in between some of these but this is a great place to start because they created a batch of videos showing off different things that you can do with it and I'll just be giving you quick summaries and my take you can watch all of these by yourself in full length if you so desire links below but hold up it doesn't even end there because look a lot of people are viewing this Channel and all of us are AI users some of us are AI power users and I was just wondering wouldn't it be amazing to find out what everybody that is watching this video actually uses this for so we're doing a brand new thing where we issue a challenge and then we have a public space where you can review all the people's submission to the challenge and the challenge is all about finding GPT 40 use cases that work for you so stick around because at the end of the video I'll give you more details and I'll tell you exactly how to participate and how to view what other people have been doing with gbt 40 so let's actually start with a clip that came out in the recent hours it's an interview of Sam Alman and he was asked the following question now check out his answer which hints at something that all of us might be doing in a few weeks here are there use cases that you've gravitated to one surprising is putting my phone on the table while I'm like really in the zone of working and then without having to like change Windows or change what I'm doing using it just like like another channel so I'm like working on something I would normally like stop what I'm doing switch to another tab Google something click around or whatever but while I'm like still doing it to just ask and get like an instant response without changing from what I was looking at on my computer that's been a surprisingly cool thing so let's talk about this one on top I think they picked this because it has the most human characteristics and it really shows the capability of this new version of jat GPT to be an AI companion matter of fact the voice is so hot that people across Twitter have been complaining what is this this is not an assistant this is a flirty girlfriend from what I can see it looks like you're in some kind of recording or production setup AI girlfriends have arrived and look this is one of the big new improvements it's way more human it doesn't just Express emotion but it also understands emotion from the phone's camera right here and here's just guessing something based on the information you provide it with which might not be very practical but some of these others definitely are so let's move on because in this example Greg Brockman actually uses two phones with two GPD 4 O's talking to each other and this shows of a capability that we already had in GPT 4 but now it's upgraded to the next level namely I'm talking about the capability of setting up multiple personas have't talked to each other with two phones you can simulate various conversations and you could apply this to your very own context this conversation might be a debate you might be pairing for or an argument you could just play it out between the two phones I mean that's amazing but also kind of freaky right and in the end they also show the ability for the app to modulate the voice so it can SN for you it can sound like a robot like they showed in the demo have a quick listen this essentially hints at the fact that you're going to be able to filter The Voice just like I have a soundboard here and I can do things like this these capabilities are going to be very surprising to most I can't wait to show my grandmother these updates now your AI assistant is going to be able to do that too and look some of these use cases might seem like a nice toy to have but if you get a little serious about it and you think about how this is applicable to some professional Fields you get something like this top comment on my latest YouTube video which as I mentioned summarizes this entire update as I asked for use cases that people are excited for male care here says melanoma detection retina exams pulmonary distress analysis this one I'll quickly have to look up ah okay so it's a diagnosis for breathing difficulties and yeah comments point out this is going to be for diagnosis not treatment but these things are amazing and admittedly this comment is a bit speculative but as you can see it clearly captured the imagination of a lot of people and talking about work-related capabilities apparently the benchmarks do translate to use cases because as we looked at in the summary video it performs better on almost all benchmarks when you compare it to the other best AI models in the market right now and this includes upgrades to Vision but also things like the code interpreter so you can actually upload files and do things like this now more effectively where you give it an Excel sheet and it analyzes the spreadsheet and does deep Technical and statistical analysis and generates chart and visualization this is a very simple prompt that you could reapply to your own charts and get these results immediately and this is not the voice assistant that might not be available to you yet this is the GPT 40 model that all plus users have now and all free users will have very soon okay and here's one that really caught my interest this comes from within the AI Advantage Community where a member used it to analyze the conflict between Drake and Kendrick not sure if you caught this recently they're beefing publicly now and they created dis tracks about each other and if you're not following this closely it gets messy very quickly there's a lot of news coming out I personally am not following this closely but look at this conversation with gbt 40 he uploaded two CSV files that included the different events that happened with dates next to them now here's an important detail these data sets also include Google Trends data with how popular were both Drake and Kendrick in Google search over the last few months so how would you compile this into some visualization I'm not exactly sure but we don't have to worry about that let's just let gp4 oh figure this out so the whole interaction starts by Daniel uploading these files and then prompting it and then with simple conversational prompts he managed to make sense of all of the data and for the conversation if you want to read this you can stop the video at any point in time I'll slowly scroll over this he managed to create visualizations on top of which he could iterate I'll show you the final result here in a second okay because this chat history doesn't include images but it basically goes ahead it Maps out everything that is in the Excel sheets it reconstructs a timeline from all the events scattered across the Excel sheets and then using the web browsing tool that is super Snappy now because we have increased speeds it adds further context so you can look for new stories add that into your conversation like so look it pulls up Wikipedia and Hollywood Life articles that recently happened and then it extends the the timeline that you provide it with now you have all of this in your conversations you can prompt it with something like redo your analysis with the added context and then it finally creates a visualization that wraps all of that information into one image and then here it is and I think this is actually really useful if you're interested in this topic you see a timeline of events dating back to the 13th of April 2024 with the first freestyle releasing and then it's all mapped against the Google Trends data on how popular the terms Drake and Kendrick were in Google search matter of fact it creates two different views with two different scales of the timelines isn't this incredible I think it is and sure it's not perfect look it made a little mistake down here with the date but this data does track with the original files that were provided to it and just think about the possibilities here you could easily be pulling Google Trends data and mapping that onto different events by yourself now really simply and it's not going to take you 20 minutes anymore because before running the code interpreter it took about a minute or two every single time running web search gave you one or two results and that also took about a minute or two if you didn't like the results you had to reprompt it and sit there for another full minute that's not the case anymore look in real time I'll put in a simple prompt and it's already searching the internet it found five sites and before I managed to finish the sentence it gave me all the links and a summary of what happens in those articles this is a massive change in user experience and the fact that they're making this available to everybody at this speed level is going to open a lot of people's eyes so how about this next video where he's preparing for an interview and he puts on a hat that might be a bit inappropriate for job interview in this interview prep use case the thing that fascinated me was actually the fact that it picked up on the fact that it had to deploy empathy to talk to him just listen to this answer this is not a neutral factual answer like take off the hat this is inappropriate have a listen what do you think Rocky that's quite a statement piece I I mean you you'll definitely stand out though maybe not in the way you're hoping for an interview okay I got it what a fantastic response and the display of emotional awareness of this new jet gbt model impressive let's move on to the next one which is the fact that it can act as a Game host and as a parallel to this they also show this other use case where you can use it as a meeting AI essentially where it facilitates the meeting and then in the end summarizes everything and I think this is absolutely amazing if you give it access to your screen and all the audio it can effectively direct the conversation and wrap up the meeting I don't know how well this will work in practice the main thing that I would be looking at here is the context limitation they only show a 2-minute demo how is this going to perform on a 1our meeting it probably doesn't have have enough context length but we have yet to find out this voice assistant is rolling out over the next weeks right now we just have the GPT 40 model without the voice assistant either way you're going to be able to use this as a game master whether it's rock paper scissors Dungeons and Dragons or the same concept but in a work context which would be a meeting let's have a brief look get ready and three two one shoot let's see those hands who won and it's another tie going back to the voice assistant use cases I even featured this one in the summarization video because I just figured that this would be so groundbreaking for Education young people or anybody trying to learn a new skill you can just open up chat GPT on let's say your iPad on one part of the screen and on the rest of the screen you're solving some problem and then by talking to it and using the pen and highlighting having a conversation like you would have with a tutor it can guide you through the entire problem step by step kind of like a human would can you find which one is the hypotenuse um I think the hypotenuse is this really long side from A to B would that be correct exactly well done amazing and look I know educational is a controversial topic we actually hosted a little post event discussion in our private AI Advantage Community where several people brought up that actually the educational sector is the one that has the most resistance to this technology because the teachers just feel like this is a direct replacement to what they're doing it lacks the human touch plus students can cheat on all these assignments homeworks Etc right so look I think that makes perfect sense but simply put a lot of people that struggle in school will have this technology available to them and they will have an alternative to Simply failing out of their classes I remember moments in high school and University were particularly on accounting and then later in University during statistics classes I was so lost I didn't even know where to start and at that point the tutor wasn't really an option cuz we simply couldn't afford it and I very vividly remembered these moments of pure desperation where I just didn't know where to go from that point I looked at the textbooks but I didn't understand anything I attended the class it didn't make any sense to me the friends that I had were busy thinking about the weekend so I was completely lost and if I had something like this I would have gave it a shot and it would have probably helped in some of those classes so just from that experience experence alone I do see the benefit of this for many people while I don't think it replaces a human teacher I think for now it's a fantastic addition to how our system works and let's be real the school system is broken in many places maybe rethinking it while considering tools like this could be the change we need just think about you learning a new piece of software and this guiding you while you do that amazing but hey at the end of the day I'm just here to point out what's new and I think this is one of the most amazing use cases now let's move on to the next one okay here's an interesting one that really was a big problem up until last it's sarcasm rarely was AI able to pick up on sarcasm and now it can actually replicate it and use sarcasm this is possible because this new model is natively multimodal or omn modal as they name it it's not fre separate steps of transcribing The Voice to Text then using chat to process the text and then afterwards turning the text back into voice it all happens in one and you get things like the capability to be sarcastic things sarcastic all the time isn't exhausting or anything I'm so excited for this H kind of incredible more of a capability than a use case but interesting nevertheless if you're enjoying this video that obviously took a lot of work to put together hit the like button it really helps the channel but with that being said let's move on to the next one okay this next one is particularly interesting and that is this accessibility feature where you're going to be using gp40 Vision to help people with no eyesight try and tell me exactly what they're doing right now please um right now the Ducks are gently gliding across the water this last part left be a little speechless I'm just going to play too I E even know when a taxi is coming with its orange light on I think I'll hail it to get home yes I spotted one just now it's heading you away on the left side of the road get ready to wave it down great job hailing that taxi I mean wow you can only imagine how transformative this would be for people without eyesight or other limitations and one interesting thought I had here was that there's situations in life where you yourself can't really see something or your attention might be divided between multiple tasks and it would be just great to have a second pair of eyes right and I found a similar idea on Twitter here where kit I suppose came up with this use case for GPD 4 where as a parent you could set up your phone to watch your kids for a second and look I can already see a comment section of like seriously you want your AI assistant to watch over your kid look fair enough maybe not in this version then you absolutely have to test it first but just this idea of like hey just let me know if my son starts crawling off to the side and you place him in the middle of the living room and then you're going to be able to leave the room for like 20 seconds I think that sounds pretty feasible but again this is for people themselves to decide and over time the tech is obviously going to be good enough for that to be a reasonable use case overall I just want you to realize that phones are soon going to turn into a second set of eyes with a certain amount of intelligence in them and that's just going to open up opportunities that we haven't even considered right now oh and while we're kind of on the topic of child care there's this one use case in here where he actually lets the phone sing a laabi and then he adjusts the voice to be softer more silent a little louder and then it comes up with a song on the spot I think this one is indisputably amazing and I guess this falls into the entertainment category but that also is a thing that you could use this for oh Majestic potato spoons of clo okay okay it's it's a little too whispery maybe maybe go like a little louder got it let's find that sweet spot oh Majestic potato in the moon sof creepy all right so let's switch gears and let's talk about something that will inarguably be useful for businesses which is a customer support rep that is going to be able to handle tasks now they do have this two-minute video in here where they use two phones to simulate a conversation between a customer and a customer support rep awesome all right I've just sent the email can you check if Joe received it and I think this one is particularly interesting to talk about because it hints at the future of these products right because for this you absolutely need Integrations with other tools and that is something that chat doesn't really offer you have actions within the gpts but doing a full customer support agent in there is just not feasible as of now you would need multiple actions you would need reliability you would need longer context length but just by them uploading this video this clearly signals to me that this is a direction that they'll take it in not as if that was any news to me I was already when gpts came out back in November I remember saying that this is the clearest sign by them that this is the future of the product it's this independent AI that have a set of tools that they can access and then use those tools to act on their own behalf by the way this was even pointed out by Sam Alman in a recent interview he said that there's really two directions this can go in one of them is kind of this assistant that will help you do your work better and the second one is a senior employee where it will not just act by itself but also have a certain level of autonomy to override your decision- making and your prioritizing because it's a senior employee so that's what you can expect from this overtime I think for now this isn't really there yet they even pointed out that this is just a proof of concept nevertheless I wanted to talk about it as it might show you a glimpse of the future and what we'll be getting soon here okay so here's another use case and this one is more development focused and this is all about integrating GPT 40 into this AI powered ID if you're not familiar that's a software that developers use to write and test code basically they were extremely fast in integrating GPT 40 I mean they took less than 24 hours to integrate it and every single chat GPT rapper as people call them will have this upgrade very quickly because all you need to do is exchange one line of code and you have this better model and all the use cases we talked about in this video will very quickly arrive in the applications that you might be using already Plus for the developers it's a 50% saving in cost as it's 50% cheaper to use all of this overnight that's pretty amazing anyway why is it significant because people across the internet report that the coding abilities are actually improved but this did cause a little discussion because it seems to be improved in certain areas and worse than others and here's just a quick example of what Sawyer Hood managed to do with this in the first 24 hours and that is rebuild Facebook Messenger with one prompt and he's reporting that GPT 40 did this in 6 seconds I mean look at that that's wild this is one HTML file we're getting closer and closer to people being able to create games of their own in just a single sentence we might not be there yet but this is going to get wild soon and talking about technical capabilities there's also this brand new ability to generate consistent text matter of fact it's so good that you can do something like text to font where you prompt it to create the basic letters and then you can keep prompting it to give you various Styles look at that futuristic here it created a Victorian style font and what that means is that they solved consistency of transferring text to other objects so as you can see here image of a coaster their logo it perfectly combines the two like a week ago you needed to know Photoshop to do this stuff pretty wild and there's all these other use cases here like taking a logo and mapping a word on top of it or writing a poem and then visualizing it as if it was handwritten look at that want it in a different color no problem and while we're on a topic character consistency is one of the main things that has been missing in many tools mid Journey added it recently but now also with GPT 40 you're able to generate a robot and then create multiple images of it like so while maintaining the same character so you can tell stories now instead of just generating one image and then if you regenerate the robot it looks like a whole different character oh and here's one more interesting capability and that is creating images that represent original with a single reference image this is not the easiest problem it has been solved by some other tools but now you will have all of this packaged into one tool so you can upload an image of yourself and then recreate it as a caricature then just a quick note before you jump into chat GPT a lot of these things will be shipping over the course of the next week so you might not have it yet the voice assistant or the availability for free to all users all of these things are coming over the next week but that's not going to stop us from exploring what's possible because I have a few more here and one of them is this 3D object synthesis okay this is something nobody really expected from them in this announcement and they didn't even mention it in the live stream it's just hidden in their blog post under this one option here so from a simple prompt and giving it view zero view 1 2 3 4 and then view five it generates five images of the same thing and then you can reconstruct that object from the six generated images so this is a combo of the consistency that we talked about a second ago with the robot and then this new capability to construct multi images into a simple 3D model here you have the same thing happening with a c line and if it wasn't clear yet they really did solve how to represent letters inside of these images all of the AI image generators could not solve text yet maybe with the exception of ideogram but their quality was not up to par with some of the leading models like Firefly mid Journey or stable diffusion Excel all of these top models couldn't do text but now you can prompt it with the exact text you want there and create mockups like this where it gets every single letter right and sure if you look at the buttons here you get some funkiness like what what kind of space bar is this what's up with these buttons but that is being nitpicky if you're creating social media content the main thing you want to get right is the fact that the text is correct and that is a capability now there's actually one more thing that I found in reference to the 3D object generation and that is the fact that you can actually use the code interpreter to create 3D objects in around 20 seconds as Min Choy reports here this table is the result of the generation and he simply created it with a simple prompt that says make a STL file of a table with four legs and random attributes 20 seconds later finished work working and here you have the result and just mind you this is the beginning of the 3D capabilities so I just want to point towards one of these top comments which is like hey just remember this was mid Journey version one in January of 2022 okay these things move fast and a simple table like this is version one so I had an idea on how to really superpower this video and how to show you what not just you can do but what also other people are already doing with this what I did is I set up a community space where you can simply sign up for free and you can share what you're using GPT 404 and at the very least you can reach what other people are using it for matter of fact I packaged this in a challenge that is now running for one week if you want to check out the details and participate in win prizes you can do so it's going to be the first link in the description but basically we created a step-by-step guide and clear judging criterias and what tools you will be using and how we recommend you present the challenge it's all in this brief guide if you want to participate but what you really need to know is this gp4 to GPT 4 is a major leap and they made GPT 40 available to everyone for free now fair enough a lot of the capabilities pointed out today like the voice assistant are not going to be available to everyone but as you can clearly see this opens up a whole new world of use cases and here in this public space that is freely available all you need to do is create a free account on the platform couldn't be any simpler and then you can share your very own use cases here win prizes or review what other people are doing with GPT 40 today like s here that is using it to reorganize his bookshelf or Justin giving it massive technical reports and seeing how well it can handle it he uploaded a detail file on the exact prompts and the workflow that he used and yes this challenge idea is just a small part of of a wider Vision that I had for AI learning community that makes sure you stay up to date with all these skills that are going to change the world over the coming months and years and we starting to do more and more in public like this challenge but as you can see this is Challenge number 19 we've been doing this for months in our paid community that is all about learning and applying these tools just one more thing to point out the main focus of the community is actually providing you with learning materials like these free guides that are also available on the website or some of these event recordings in this one for example I show you how to integrate stripe checkout into a GPT and I basically bundled everything I know I have in to here so in the Learning Center for paid community members you actually get the full prompt engineering course you get 40 hours of event recordings and much more so there you go a lot of use cases generated by the AI Advantage Community a bunch of free AI learning resources and will keep you updated on the YouTube as a lot of these capabilities shipped to the public I sincerely hope this video was helpful to you and if you want even more use cases I'll be doing a live stream on the 21st of May where we evaluate all the results of this Challenge and have a look at all the use cases that people submitted to this challenge that I issued all right I hope you have a great da
